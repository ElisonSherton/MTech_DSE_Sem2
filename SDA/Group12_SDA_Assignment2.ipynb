{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7e322b-07c8-4bf7-adf0-8a72b67c4195",
   "metadata": {
    "tags": []
   },
   "source": [
    "|Name|Contribution|\n",
    "|--|--|\n",
    "|Nayak Vinayak Vinod|100%|\n",
    "|Ajith Praveen R|100%|\n",
    "|Nayak Uttam Jnaneshwar Reshma|100%|\n",
    "\n",
    "# Question 1\n",
    "\n",
    "\n",
    "An application collects large quantities of machine generated data and stores it. The data collected are periodically analysed to generate critical systems warnings. Due to the sensitive nature of data, we would like to ensure as much availability as possible.\n",
    "\n",
    "Assume that there are 8 servers in each rack, there are 16 such racks and each machine is having hard disk size of 4 GB. Block size is 128MB. How many data blocks can be stored if we use RF=3 and RF=4? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae69f1b8-ddd5-4224-abdb-3032d1efbd5a",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Per Rack calculation\n",
    "\n",
    "- Servers per rack = 8\n",
    "- Size of one server = 4 GB\n",
    "- Size of a block = 128 MB\n",
    "\n",
    "With this info, we can say\n",
    "\n",
    "$\\text{Blocks per rack} = \\frac{\\text{Total Memory Per Rack}}{\\text{Block Size}}$\n",
    "\n",
    "$\\therefore \\text{Blocks per rack} = \\frac{\\text{Servers per rack x Size of one server}}{\\text{Block  Size}}$\n",
    "\n",
    "$\\therefore \\text{Blocks per rack} = \\frac{8 \\times 4 \\text{ GB}}{128 \\text{ MB}}$\n",
    "\n",
    "$\\therefore \\text{Blocks per rack} = \\frac{8 \\times 4 \\times 2^{30}}{128 \\times 2^{20}}$\n",
    "\n",
    "$\\therefore \\text{Blocks per rack} = 256$\n",
    "\n",
    "Since we have 16 such racks, the total number of blocks of memory available to us are $16 \\times 256 = 4096$ blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2025401-d3a7-4ae0-8b18-bd6bb7822852",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9932498a-1b06-4ec6-9b6a-0ba719201a4d",
   "metadata": {},
   "source": [
    "We are aware of the HDFS Rack awareness strategy which states the following\n",
    "\n",
    "- There should not be more than 1 replica on the same Datanode.\n",
    "- More then 2 replicaâ€™s of a single block is not allowed on the same Rack.\n",
    "- The number of racks used inside a Hadoop cluster must be smaller than the number of replicas.\n",
    "\n",
    "In accordance with the above guidelines and using a Replication factor of 3, we could come up with the following scheme.\n",
    "\n",
    "![](rack_awareness_rf3.png)\n",
    "\n",
    "- We can group racks into sets of 3. \n",
    "- Rack 1 can save 128 distinct blocks and a single copy of them on the same rack.\n",
    "- Corresponding to these 128 blocks, one replica can be stored in Rack 2. This ensures that all these 128 blocks have an RF = 3.\n",
    "- Rack 3 can save 128 distinct blocks with a single copy of them on the same rack.\n",
    "- Corresponding to these 128 blocks on Rack3, one replica can be stored in Rack 2. This ensures that all these 128 blocks have an RF = 3.\n",
    "- This means that between 3 racks, we can store a total of 128 + 128 = 256 blocks.\n",
    "- Since we have 16 racks, and the closest multiple of 3 without going over is 5, we can have 5 groups of 3 racks each which store 256 * 5 = 1280 blocks and one rack would stay unutilized because we cannot store all 3 replicas of a block on the same server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3e2f6-2cce-4f31-a525-e8a14942c11f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7c7e7-e58b-436a-8dee-75848d1b3786",
   "metadata": {},
   "source": [
    "Similarly, for a Replication factor of 4, we could argue as follows\n",
    "\n",
    "![](rack_awareness_rf4.png)\n",
    "\n",
    "- Group the racks in sets of 2.\n",
    "- Consider Rack 1 and Rack 2. Once we store a block on Rack 1, we can store one replica of the same on Rack 1 and two replicas on Rack 2.\n",
    "- This means that 256 / 2 = 128 blocks in all can be stored on a combination of 2 racks.\n",
    "- Since we can group the 16 racks into 8 sets of 2 racks each, we can store 8 * 128 = 1024 blocks of data on the given hadoop cluster.    \n",
    "\n",
    "\n",
    "**Answer**\n",
    "\n",
    "For the given hadoop cluster with \n",
    "\n",
    "- *Replication Factor = 3, we can store a max of 1280 blocks but 256 blocks are unutilized*\n",
    "- *Replication Factor = 4, we can store a max of 1024 blocks with the complete utilization of all blocks in the rack.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a205c8f-23f1-4108-97f9-b69b372874ca",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2347d3-5835-4e4f-b142-5e85f30a6c19",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Use map reduce to compute the mean of a set of values stored in a list L.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "\n",
    "*Pseudocode*\n",
    "\n",
    "1. Load the data into memory in an array/list L\n",
    "2. Define a function which which takes an index and maps the same to the value in the list L at that index\n",
    "```python\n",
    "def Lambda(x):\n",
    "    return L[x]\n",
    "# apply Lambda on a list of chronological indices spanning length of list L\n",
    "mapped_list = [Lambda(i) for i in range(len(L))]\n",
    "```\n",
    "3. Use the binary operator sum to reduce the elements of list L into a single number i.e. summation of all the values in the list and eventually divide it by the number of elements in the list.\n",
    "```python\n",
    "# apply reduce sigma on Lambda(L) and divide it by number of elements\n",
    "mean = sum(mapped_list) / len(mapped_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16694f2d-240e-40cc-b610-a14b6d92c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped List: [3, 1, 4, 1, 5, 9, 2, 6, 5, 3]\n",
      "Mean of all elements in the list: 3.9\n"
     ]
    }
   ],
   "source": [
    "# Define the list of values whose mean needs to be computed\n",
    "data = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3]\n",
    "\n",
    "# Map stage\n",
    "mapping_function = lambda x: data[x]\n",
    "mapped_list = [mapping_function(x) for x in range(len(data))]\n",
    "print(f\"Mapped List: {mapped_list}\")\n",
    "\n",
    "# Reduce stage\n",
    "mu = sum(mapped_list) / len(mapped_list)\n",
    "print(f\"Mean of all elements in the list: {mu}\")\n",
    "\n",
    "# Check if what we get is what is expected\n",
    "assert mu == 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba8cb8-77bb-4204-82f8-912ce805e9e4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb727e9f-5b78-489c-9fbe-43ac2e5e0b49",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "### Solution\n",
    "\n",
    "Using map-reduce, given a list of tuples L containing the actual and expected values, compute the mean square error.\n",
    "\n",
    "$\\text{MSE} = \\frac{1}{n}\\Sigma_{i=1}^{N}(Y_i - \\hat{Y_i})^2$\n",
    "\n",
    "where\n",
    "\n",
    "- MSE: Mean Squared Error\n",
    "- n: Number of data points\n",
    "- $Y_i$: True target value\n",
    "- $\\hat{Y_i}$: Predicted target value \n",
    "\n",
    "*Pseudocode*\n",
    "\n",
    "1. Load the data into memory in an array/list L\n",
    "2. Define a function which which takes one tuple from the list and computes the square of the difference of it's contents\n",
    "```python\n",
    "def Lambda(t):\n",
    "    true, pred = t[0], t[1]\n",
    "    return (true - pred) ** 2\n",
    "# apply Lambda on a list of chronological indices spanning length of list L\n",
    "mapped_list = [Lambda(t) for t in L]\n",
    "```\n",
    "3. Use the binary operator sum to reduce the elements of mapped list into a single number i.e. summation of all the values in the list and eventually divide it by the number of elements in the list.\n",
    "```python\n",
    "# apply reduce sigma on Lambda(L) and divide it by number of elements\n",
    "mean_squared_error = sum(mapped_list) / len(mapped_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d2bba5-3040-4858-ac86-a8839f3480be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatted list: [(3, 4), (1, 0), (4, 3), (1, 5), (5, 1), (9, 2), (2, 5), (6, 4), (5, 3), (3, 1)]\n",
      "Mapped list: [1, 1, 1, 16, 16, 49, 9, 4, 4, 4]\n",
      "Mean squared error of elements in the tuplized list: 10.5\n"
     ]
    }
   ],
   "source": [
    "true_values = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3]\n",
    "predicted_values = [4, 0, 3, 5, 1, 2, 5, 4, 3, 1]\n",
    "\n",
    "tuplized_list = list(zip(true_values, predicted_values))\n",
    "print(f\"Reformatted list: {tuplized_list}\")\n",
    "\n",
    "# Map the tuples to a squared diff function\n",
    "def Lambda(t):\n",
    "    true, pred = t[0], t[1]\n",
    "    return (true - pred) ** 2\n",
    "mapped_list = [Lambda(t) for t in tuplized_list]\n",
    "print(f\"Mapped list: {mapped_list}\")\n",
    "\n",
    "# apply reduce sigma on Lambda(L) and divide it by number of elements\n",
    "mean_squared_error = sum(mapped_list) / len(mapped_list)\n",
    "print(f\"Mean squared error of elements in the tuplized list: {mean_squared_error}\")\n",
    "\n",
    "# Check the mean squared error should equal expected mean squared error\n",
    "assert mean_squared_error == 10.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
